{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Usage:\n",
    "\n",
    "1:  Create a dataset myDataset = dataset(setName, sigVars, bkdVars, sigWts, bkdWts, varNums, varNames)\n",
    "\n",
    "        sigVars, bkdVars, sigWts, bkdWts are lists of variable values.\n",
    "        varNums is just a list of integers for the variables\n",
    "        varMames is a list of names for the variables\n",
    "\n",
    "2:  Create a run and pass it a dataset: myRun = run(myDataset).\n",
    "\n",
    "        A run holds all information about all nodes and all playouts for\n",
    "        all playouts that you have run on it (see below).\n",
    "\n",
    "3:  Execute one or more playouts for your run: playouts(myRun,100,[-1],50)\n",
    "\n",
    "        myRun: is the run to execute playouts on\n",
    "        100: is the number of events to use per playout\n",
    "        [-1]: describes the type of playouts to execute (see below)\n",
    "        50: is the number of playouts to execute\n",
    "\n",
    "        playout types:\n",
    "            [-1] is compressed tree.  I.e. nodes are included/excluded\n",
    "            based on their performance independent of what other\n",
    "            variables were inc/exc.\n",
    "\n",
    "            [-2] is full tree, but see parameter settings for details on\n",
    "            this.\n",
    "\n",
    "            [i,j,k] Any other list for this argument is interpreted as\n",
    "            fixed-path running.  All playouts will use only variable\n",
    "            numbers i,j,k (counting from zero)\n",
    "\n",
    "4:  Execute more playouts on the run as needed.\n",
    "\n",
    "    N.B. Once a run object is created, you can continue to run playouts\n",
    "    on it, and it will continue to accrue statistics from the playouts\n",
    "    and add them to the runs stored information.  So, you could keep\n",
    "    calling playouts(myRun,100,[-1],50) if after looking at the reports\n",
    "    (see below), you decide that you want to continue with more playouts\n",
    "    starting from the current state of the run.\n",
    "\n",
    "5:  Print text-based report textReports(myRun,i)\n",
    "\n",
    "        myRun specifies the run you want to report on, and  i indicates\n",
    "        how many playouts you want to include in the per-playout portion\n",
    "        of the report.  0 means all.\n",
    "\n",
    "6:  Make plot-based reports plotReports(myRun,0,makePDF=False)\n",
    "\n",
    "        Makes a bunch of plots to the screen if you're in something like\n",
    "        jupyter or have XQuartz running.  If you set makePDF=True, then\n",
    "        it will also send the plots to a file.\n",
    "\n",
    "Extra:\n",
    "\n",
    "There are additional parameters you can include when creating a run:\n",
    "\n",
    "    getEvalParm: Both sides of a node must be visited this many\n",
    "        times before either gate can be closed.  This is a subtle and\n",
    "        important parameter for full-tree mode.  In full-tree mode,\n",
    "        closing a gate on one of the variables means that if any node\n",
    "        anywhere in the tree has minVisistsForGateEval visits to both\n",
    "        its include and exclude sides, then the variable will be\n",
    "        evaluated for possible closing one of the gates.  However, when\n",
    "        that gate is closed, that variable is now always included or\n",
    "        excluded no matter where it appears in the tree in future path\n",
    "        searches.  The nice feature of this approach is that initially,\n",
    "        only variables near the top of the tree (i.e., small var\n",
    "        numbers) can be shut off, since they are the nodes that will\n",
    "        reach the threshold first.  However, as low-numbered variables\n",
    "        have one of their gates closed, gates further down the tree will\n",
    "        get more visits.  So the gate actions will propagate down the\n",
    "        tree as playouts increase.\n",
    "\n",
    "        If one wants a proper full-tree mode with no gates ever being\n",
    "        closed, just set this parameter to be very large.  There is\n",
    "        currently no way to turn off gates in individual nodes in a full\n",
    "        tree.\n",
    "\n",
    "    nodeEvalParm: Only used in compress-tree mode\n",
    "        Both sides of a node must be visited this many\n",
    "        times before policy can be implemented to choose a side. Below\n",
    "        this value, we flip a coin to choose a side.\n",
    "\n",
    "    nParallel: Number of playouts that will be batched in parallel\n",
    "        processing.  Speeds the code significantly, but do not set this\n",
    "        to be greater than 8 without reading the longer comment in the\n",
    "        code itself, even if you are on a machine with more than eight\n",
    "        cores.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Jesse Ernst: Version 2.1 16Nov2019\n",
    "import platform\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import multiprocessing as mp\n",
    "import math\n",
    "import MLP\n",
    "\n",
    "print(\"python : \" + platform.python_version())\n",
    "print(\"numpy : \" + np.__version__)\n",
    "print(\"pandas : \" + pd.__version__)\n",
    "print(\"scipy : \" + scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    \"\"\"Set of events\"\"\"\n",
    "\n",
    "    def __init__(self, setName, sigVars, bkdVars, sigWts, bkdWts, varNums, varNames):\n",
    "        self.setName = setName\n",
    "        self.sigVars = sigVars\n",
    "        self.bkdVars = bkdVars\n",
    "        self.sigWts = sigWts\n",
    "        self.bkdWts = bkdWts\n",
    "        self.sigWtMax = max(sigWts)[0]\n",
    "        self.sigWtMin = min(sigWts)[0]\n",
    "        self.bkdWtMax = max(bkdWts)[0]\n",
    "        self.bkdWtMin = min(bkdWts)[0]\n",
    "        self.varNums = varNums\n",
    "        self.varNames = varNames\n",
    "\n",
    "        # sample efficiency is the fraction of events you'd expect to pass weighted sampling.\n",
    "        # One extreme is if all weights in the file are equal, then it should be 1.\n",
    "        # The other extreme is if a few events have large weights and all the others have small weights.  Then,\n",
    "        # the sampleEff value would tend toward zero.\n",
    "        self.sigSampleEff = np.mean([x[0] / self.sigWtMax for x in self.sigWts])\n",
    "        self.bkdSampleEff = np.mean([x[0] / self.bkdWtMax for x in self.bkdWts])\n",
    "\n",
    "        assert (len(varNames) == len(varNums))\n",
    "        assert (len(sigVars) == len(sigWts))\n",
    "        assert (len(bkdVars) == len(bkdWts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class run:\n",
    "    \"\"\"One run of the data through multiple paths\"\"\"\n",
    "\n",
    "    def __init__(self, locDataset, gateEvalParm=20, nodeEvalParm=5, nParallelParm=8):\n",
    "        self.dataset = locDataset\n",
    "        self.varNums = locDataset.varNums\n",
    "        self.varNames = locDataset.varNames\n",
    "\n",
    "        # Both sides of a node must be visited this many times before either gate can be closed.\n",
    "        self.minVisitsForGateEval = gateEvalParm\n",
    "\n",
    "        # Both sides of a node must be visited this many times before policy can be implemented to choose a side.  Below\n",
    "        # this value, we flip a coin to choose a side.\n",
    "        self.minVisitsForNodeEval = nodeEvalParm\n",
    "\n",
    "        # Number of playouts to run in parallel using python's multiprocessing calls.  One can't just launch all the\n",
    "        # playouts into one big multiprocessing pool because each playout needs to make its own dataset that holds just\n",
    "        # the variables it is using and is a random selection of all the events (since each playout runs only on a\n",
    "        # subsample of events).  Typically, I'd expect that this should be set to something around the number of cores,\n",
    "        # though it might have to be lower if you are running a large number of events in a playout, and don't have\n",
    "        # enough memory to hold as many copies of the data as you have cores in the machine.\n",
    "        # CAUTION: You also should not set this too high, because information on nodes paths are not updated until all\n",
    "        # parallel processes are completed.  I.e., playouts are run in batches of nParallal.  Thus if you set it too\n",
    "        # high, you'll be running many times w/o new information about which path to try next.  In particular, depending\n",
    "        # on the tree type and the variable policy, you could wind up running the same exact path nParallel times.\n",
    "        # That's not necessarily bad, as it'll improve your statistics w/o running-time penalty, but it's not going\n",
    "        # to give you any more paths (though I guess you could set nEvents per playout smaller if you knew each was\n",
    "        # going to be run nParallel times).\n",
    "        self.nParallel = nParallelParm\n",
    "        self.nodesColl = nodesCollection(self)\n",
    "        self.pathStatsColl = pathStatsColl()\n",
    "        self.playoutList = []\n",
    "        self.nFallbackPath = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nodesCollection:\n",
    "    \"\"\"A collection of nodes\"\"\"\n",
    "\n",
    "    def __init__(self, locRun):\n",
    "        self.run = locRun\n",
    "\n",
    "        # This will be a nested dictionary for all nodes.  The outer key is var number.\n",
    "        # The inner key will be locationID for the node.\n",
    "        self.all = {}\n",
    "        for i in range(len(locRun.dataset.varNums)):\n",
    "            varNum = locRun.dataset.varNums[i]\n",
    "            self.all[varNum] = {}  # Initially an empty dictionary for each var number.  Will be filled over playouts\n",
    "\n",
    "        # This will be a dictionary of summary nodes (one per variable) with var number as key\n",
    "        self.smry = {}\n",
    "        for i in range(len(locRun.dataset.varNums)):\n",
    "            varNum = locRun.dataset.varNums[i]\n",
    "            varName = locRun.dataset.varNames[i]\n",
    "            self.smry[varNum] = node(varNum, varName, locRun)  # Summary nodes for each var to hold stats.\n",
    "\n",
    "    def getNode(self, varNum, nodeID):\n",
    "        \"\"\"Extracts the node with the given variable number and nodeID from the nodesCollection.\n",
    "        Creates it if it doesn't already exist in the dictionary\"\"\"\n",
    "        # From the nested dictionary, get the dictionary for this particular variable\n",
    "        varDict = self.all[varNum]\n",
    "        if nodeID not in varDict:  # requested node not yet in dict.  So create it then add it.\n",
    "            newNode = node(varNum, self.run.dataset.varNames[varNum], self.run, nodeID)\n",
    "            varDict[nodeID] = newNode\n",
    "        myNode = varDict[nodeID]  # Get the node from the dictionary.\n",
    "        return myNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    \"\"\"One node corresponds to one variable.  Each node has a variable\n",
    "    that will either be included or excluded in any given path.  Each\n",
    "    node also has a pair of gates that control whether or not the node's\n",
    "    variable should always be included or always be excluded from\n",
    "    paths.\"\"\"\n",
    "\n",
    "    def __init__(self, varNum, varName, locRun, nodeID=-999):\n",
    "        self.varNum = varNum\n",
    "        self.varName = varName\n",
    "        self.run = locRun\n",
    "        self.nodeID = nodeID\n",
    "        self.nVisitsIncPath = 0\n",
    "        self.nVisitsExcPath = 0\n",
    "        self.sumScoreIncPath = 0\n",
    "        self.sumScoreExcPath = 0\n",
    "        self.sumScoreSqIncPath = 0\n",
    "        self.sumScoreSqExcPath = 0\n",
    "        self.incPathOpen = True\n",
    "        self.excPathOpen = True\n",
    "\n",
    "    def __copy__(self):\n",
    "        newNode = node(self.varNum, self.varName, self.run, self.nodeID)\n",
    "        newNode.nVisitsIncPath = self.nVisitsIncPath\n",
    "        newNode.nVisitsExcPath = self.nVisitsExcPath\n",
    "        newNode.sumScoreIncPath = self.sumScoreIncPath\n",
    "        newNode.sumScoreExcPath = self.sumScoreExcPath\n",
    "        newNode.sumScoreSqIncPath = self.sumScoreSqIncPath\n",
    "        newNode.sumScoreSqExcPath = self.sumScoreSqExcPath\n",
    "        newNode.incPathOpen = self.incPathOpen\n",
    "        newNode.excPathOpen = self.excPathOpen\n",
    "        return newNode\n",
    "\n",
    "    def nodeOverallScore(self, included):\n",
    "        \"\"\"Computes the overall score for a node for either including or excluding it\"\"\"\n",
    "        if included:  # score for results when node is included\n",
    "            mean, errOnMean, stdev = \\\n",
    "                meanSigma(self.nVisitsIncPath, self.sumScoreIncPath, self.sumScoreSqIncPath)\n",
    "        else:  # score for results when node is excluded\n",
    "            mean, errOnMean, stdev = \\\n",
    "                meanSigma(self.nVisitsExcPath, self.sumScoreExcPath, self.sumScoreSqExcPath)\n",
    "        return mean, errOnMean\n",
    "\n",
    "    def includeVarPolicy(self, pathType, cpParm):\n",
    "        \"\"\"Given a node and a pathType, implements policy for choosing whether to\n",
    "        include or exclude the node's variable based on the nodes current performance and visits.\n",
    "\n",
    "        In full tree mode, you look at the inc/exc results for the specific node\n",
    "        in the full tree.\n",
    "\n",
    "        In compressed tree mode, you look at the inc/exc summary node\n",
    "        for that variable. (The information in the summary node for that variable is\n",
    "        a projection of all the full-tree nodes with the same variable number).\n",
    "\n",
    "        In fixed path mode, you just inc/exc a variable based on the user-requested variables.\n",
    "\n",
    "        In coin-flip mode, you randomly decide whether or not to include the variable.\n",
    "        \"\"\"\n",
    "        includeVar = None  # initialize to prevent uninitialized warning\n",
    "        if self.incPathOpen and not self.excPathOpen:  # exclude gate is closed\n",
    "            includeVar = True\n",
    "        elif self.excPathOpen and not self.incPathOpen:  # include gate is closed\n",
    "            includeVar = False\n",
    "        elif self.incPathOpen and self.excPathOpen:  # both gates are open, so you need to make comparison\n",
    "            if pathType[0] == -1:  # compressed-tree mode\n",
    "                if self.nVisitsIncPath < self.run.minVisitsForNodeEval or \\\n",
    "                        self.nVisitsExcPath < self.run.minVisitsForNodeEval:\n",
    "                    includeVar = np.random.uniform(0.0, 1.0, 1)[0] >= 0.5  # flip coin\n",
    "                else:  # both have been visited enough, so compare inc to exc\n",
    "                    banditScoreInc, banditScoreExc = banditScore(self, cpParm)\n",
    "                    includeVar = (banditScoreInc >= banditScoreExc)\n",
    "            elif pathType[0] == -2:  # full-tree mode\n",
    "                if self.nVisitsIncPath == 0 and self.nVisitsExcPath == 0:\n",
    "                    includeVar = (np.random.uniform(0.0, 1.0, 1)[0] >= 0.5)  # flip a coin\n",
    "                elif self.nVisitsIncPath == 0 and self.nVisitsExcPath != 0:  # only exclude has been visited\n",
    "                    includeVar = True\n",
    "                elif self.nVisitsIncPath != 0 and self.nVisitsExcPath == 0:  # only include has been visited\n",
    "                    includeVar = False\n",
    "                else:  # both have been visited, so make comparison to choose inc vs. exc\n",
    "                    banditScoreInc, banditScoreExc = banditScore(self, cpParm)\n",
    "                    includeVar = (banditScoreInc >= banditScoreExc)\n",
    "            elif pathType[0] == -9:  # coin-flip mode\n",
    "                includeVar = (np.random.uniform(0.0, 1.0, 1)[0] >= 0.5)  # flip a coin\n",
    "            elif pathType[0] >= 0:  # fixed-path mode\n",
    "                pass\n",
    "            else:  # unknown mode\n",
    "                print(\"ERROR: unknown variable-comparison mode\")\n",
    "                sys.exit()\n",
    "        else:\n",
    "            print(\"ERROR: Something is wrong, the gates on both sides are closed\")\n",
    "            sys.exit()\n",
    "\n",
    "        if pathType[0] >= 0:  # for fixed-path running, ignore all above calculations and just inc/exc based on list.\n",
    "            includeVar = True if self.varNum in pathType else False\n",
    "        return includeVar\n",
    "\n",
    "    def nodeStatsUpdate(self, runScore, included):\n",
    "        \"\"\"Given a node, a score for a playout, and whether the node\n",
    "        was included or excluded from that playout, update the statistics\n",
    "        on the node's performance.\"\"\"\n",
    "        if included:\n",
    "            self.sumScoreIncPath += runScore\n",
    "            self.sumScoreSqIncPath += runScore ** 2\n",
    "            self.nVisitsIncPath += 1\n",
    "        else:\n",
    "            self.sumScoreExcPath += runScore\n",
    "            self.sumScoreSqExcPath += runScore ** 2\n",
    "            self.nVisitsExcPath += 1\n",
    "\n",
    "        self.setGates()  # update which gates should be open for the node\n",
    "        return\n",
    "\n",
    "    def nodeStatsAdd(self, secondNode):\n",
    "        \"\"\"Add the stats from a second node to this node.\"\"\"\n",
    "        self.nVisitsIncPath += secondNode.nVisitsIncPath\n",
    "        self.nVisitsExcPath += secondNode.nVisitsExcPath\n",
    "        self.sumScoreIncPath += secondNode.sumScoreIncPath\n",
    "        self.sumScoreExcPath += secondNode.sumScoreExcPath\n",
    "        self.sumScoreSqIncPath += secondNode.sumScoreSqIncPath\n",
    "        self.sumScoreSqExcPath += secondNode.sumScoreSqExcPath\n",
    "        return\n",
    "\n",
    "    def setGates(self):\n",
    "        \"\"\"Consider closing either the include or the exclude side of a\n",
    "        node depending on various stats that the node has shown during\n",
    "        playouts so far.  Note that a closed path could be reopened\n",
    "        in the future if the performance of the side that has remained\n",
    "        open falls sufficiently.\"\"\"\n",
    "        if self.nVisitsIncPath < self.run.minVisitsForGateEval or self.nVisitsExcPath < self.run.minVisitsForGateEval:\n",
    "            self.incPathOpen = True\n",
    "            self.excPathOpen = True\n",
    "        else:  # We have passed the threshold number of playouts on each side and so can make gate-closing decision\n",
    "            meanInc, meanIncErr = self.nodeOverallScore(True)\n",
    "            meanExc, meanExcErr = self.nodeOverallScore(False)\n",
    "            diffOfMeans = meanInc - meanExc\n",
    "            errOnDiffOfMeans = (meanIncErr ** 2 + meanExcErr ** 2) ** 0.5\n",
    "            nSigmaDiff = abs(diffOfMeans / errOnDiffOfMeans)\n",
    "\n",
    "            # The goal with the following block is to permanently include a variable unless it is clearly harmful.\n",
    "            # We now have enough playouts through both sides to judge, so close include gate only if excluding is\n",
    "            # meaningfully better than including.  Otherwise, close the exclude gate.\n",
    "            if (meanExc > meanInc) and nSigmaDiff > 1.0:\n",
    "                self.incPathOpen = False\n",
    "                self.excPathOpen = True\n",
    "            else:\n",
    "                self.incPathOpen = True\n",
    "                self.excPathOpen = False\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pathStatsColl:\n",
    "    \"\"\"Objects that collect information on multiple paths over multiple playouts\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pathStatsDict = dict()\n",
    "\n",
    "    def pathStatsUpdate(self, locPath, score):\n",
    "        \"\"\"Given a path and a score, add that information either to a\n",
    "        new entry in the dictionary, or update the existing entry\"\"\"\n",
    "        locPathIdStr, locPathIdDec = locPath.pathId()  # get the ID num and string for the path.\n",
    "        if locPathIdStr not in self.pathStatsDict:  # If path doesn't yet have pathstats obj in dict then create/add it.\n",
    "            newStats = pathStats(locPath)\n",
    "            self.pathStatsDict[locPathIdStr] = newStats\n",
    "        # retrieve path and update info\n",
    "        currStats = self.pathStatsDict[locPathIdStr]\n",
    "        currStats.nVisits += 1\n",
    "        if score < currStats.minScore: currStats.minScore = score\n",
    "        if score > currStats.maxScore: currStats.maxScore = score\n",
    "        currStats.sumScore += score\n",
    "        currStats.sumScoreSq += score ** 2\n",
    "        currStats.mean, currStats.errOnMean, currStats.stdev = \\\n",
    "            meanSigma(currStats.nVisits, currStats.sumScore, currStats.sumScoreSq)\n",
    "        self.pathStatsDict[locPathIdStr] = currStats\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pathStats:\n",
    "    \"\"\"Collection of information about a path\"\"\"\n",
    "\n",
    "    def __init__(self, locPath):\n",
    "        self.pathIdStr, self.pathIdDec = locPath.pathId()\n",
    "        self.nVisits = 0\n",
    "        self.maxScore = 0\n",
    "        self.minScore = 9e9\n",
    "        self.sumScore = 0\n",
    "        self.sumScoreSq = 0\n",
    "        self.mean = 0\n",
    "        self.errOnMean = 0\n",
    "        self.stdev = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class path:\n",
    "    \"\"\"A path through the list of all variables.  One path corresponds\n",
    "    to one specific set of nodes whose variables should be included in\n",
    "    the path.\"\"\"\n",
    "\n",
    "    def __init__(self, locRun, pathType, cpParm):\n",
    "        self.locRun = locRun\n",
    "        self.pathType = pathType\n",
    "        self.nodesColl = locRun.nodesColl\n",
    "        self.allVars = locRun.dataset.varNums\n",
    "        self.nodesList, self.incVars, self.excVars = self.chooseNodes(self.pathType, cpParm)\n",
    "        if len(self.incVars) == 0:\n",
    "            self.locRun.nFallbackPath += 1\n",
    "            while len(self.incVars) == 0:  # If you got zero included variables, try again using coin-flip mode.\n",
    "                self.nodesList, self.incVars, self.excVars = self.chooseNodes([-9], cpParm)\n",
    "\n",
    "    def chooseNodes(self, locPathType, cpParm):\n",
    "        \"\"\"Choose a path from the full set of variables. The pathtype\n",
    "        variables changes how the code chooses nodes when the includeVarPolicy is called.\"\"\"\n",
    "\n",
    "        assert len(locPathType) > 0, 'No path-type directive given'\n",
    "        # This code is somewhat subtle.  You loop over all the variables.  For each variable (starting at the top\n",
    "        # of the tree) you get the corresponding node.  You then evaluate the variable controlled by the node\n",
    "        # to see if you include it.  THEN, that decision gets appended onto the incVars and excVars array.  Now those\n",
    "        # new values for incVars and excVars will determine the node that you take during the next iteration of the loop\n",
    "        nodesList = []\n",
    "        incVars = []\n",
    "        excVars = []\n",
    "        for varNum in self.allVars:\n",
    "            # Get the nodeID and then the node that that needs to be evaluated to see if its variable will be included.\n",
    "            currNodeID = getNodeID(incVars, varNum)\n",
    "            currNode = self.nodesColl.getNode(varNum, currNodeID)\n",
    "            nodesList.append(currNode)\n",
    "\n",
    "            # In compressed-tree mode, the node to evaluate for inc/exc is the summary node, not the tree node\n",
    "            if locPathType[0] == -1:\n",
    "                evalNode = self.nodesColl.smry[varNum]\n",
    "            else:  # Not pathType mode of -1\n",
    "                evalNode = currNode\n",
    "\n",
    "            if evalNode.includeVarPolicy(locPathType, cpParm):  # inc/exc variable based on nodes info and the policy\n",
    "                incVars.append(varNum)\n",
    "            else:  # do not include the variable\n",
    "                excVars.append(varNum)\n",
    "        return nodesList, incVars, excVars\n",
    "\n",
    "    def getIncVarNames(self):\n",
    "        \"\"\"report names of the variables included in path\"\"\"\n",
    "        varNameList = []\n",
    "        for i in self.incVars:\n",
    "            varNameList.append(i.varName)\n",
    "        return varNameList\n",
    "\n",
    "    def pathId(self):\n",
    "        \"\"\"Given a path, returns decimal and string representation of\n",
    "        binary where the binary representation shows shows which\n",
    "        variables are included and excluded\"\"\"\n",
    "        pathIdDecimal = 0\n",
    "        for i in self.incVars:\n",
    "            pathIdDecimal += 2 ** i\n",
    "        pathIdStr = np.binary_repr(pathIdDecimal, width=len(self.allVars))\n",
    "        return pathIdStr, pathIdDecimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class playouts:\n",
    "    \"\"\"make one or more playouts, run them in multiple threads, then update statistics when all are complete\"\"\"\n",
    "\n",
    "    def __init__(self, locRun, eventsPerPlayout, pathType, cpParm=0.7071, numPlays=1):\n",
    "        nParallel = locRun.nParallel\n",
    "        numPlaysRemaining = numPlays\n",
    "        # In the bandit formula, this parameter controls tendency to explore new paths vs exploiting existing ones.\n",
    "        # 1/sqrt(2) is the default (from the Browne paper).  cpParm=0 would cause tree to only follow best path, and\n",
    "        # cpParm >> typical max values of MI (i.e. cpParm >> 1) would cause it to always balance number of visits\n",
    "        # independent of score.  Although, 1/sqrt(2) is the default in the paper, they do say that adjustments are\n",
    "        # likely needed.  One can use the banditPenaltyDiff utility function in the code to understand the impact of\n",
    "        # different values of cpParm.\n",
    "\n",
    "        while numPlaysRemaining > 0:\n",
    "            # make list of playouts along with a prepared dataset for each.\n",
    "            playList = [playout(locRun, eventsPerPlayout, pathType, cpParm)\n",
    "                        for _ in range(min(numPlaysRemaining, nParallel))]\n",
    "\n",
    "            # == The following line just does single-threaded data prep ===================\n",
    "            # datasetList = [i.prepData() for i in playList]  # create dataset for each playout\n",
    "            # == The following four lines do multi-threaded data prep ====================\n",
    "            myPool = mp.Pool(processes=nParallel)  # make multiprocess pool with nParallel processes\n",
    "            datasetList = myPool.map(playout.prepData, playList)  # fill a list the score results from the processes\n",
    "            myPool.close()  # close/cleanup the pool\n",
    "            myPool.join()  # close/cleanup the pool\n",
    "\n",
    "            # Process sets in parallel to get nParallel scores.\n",
    "            myPool = mp.Pool(processes=nParallel)  # make multiprocess pool with nParallel processes\n",
    "            scores = myPool.map(go, datasetList)  # fill a list the score results from the processes\n",
    "            myPool.close()  # close/cleanup the pool\n",
    "            myPool.join()  # close/cleanup the pool\n",
    "\n",
    "            for i, val in enumerate(playList):  # loop over playouts in the playout list and update score and paths\n",
    "\n",
    "                val.score = scores[i]  # attach the score to the path\n",
    "\n",
    "                updateNodes(val.path, val.score)  # update nodes by passing current path and its score\n",
    "\n",
    "                locRun.pathStatsColl.pathStatsUpdate(val.path, val.score)  # add path information\n",
    "\n",
    "                locRun.playoutList.append(val)  # add current playout to the run's playout list\n",
    "\n",
    "            numPlaysRemaining -= nParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class playout:\n",
    "    \"\"\"one pass through the data along a specific path\"\"\"\n",
    "\n",
    "    def __init__(self, locRun, eventsPerPlayout, pathType, cpParm):\n",
    "        self.pathType = pathType\n",
    "        self.cpParm = cpParm\n",
    "        self.dataset = locRun.dataset\n",
    "        self.path = path(locRun, self.pathType, self.cpParm)\n",
    "        # Each playout gets its own copy of the nodes in the playout.\n",
    "        # This is so that future playouts won't change the information in this playout's copy.\n",
    "        # This allows us to see the all the nodes' info for each playout at the time the playout was run.\n",
    "        if pathType[0] != -1:  # Not compressed-tree mode, so playlist gets copy of nodes along the path\n",
    "            self.nodesList = [i.__copy__() for i in self.path.nodesList]\n",
    "        else:  # Compressed-tree mode.  Playlist's node copy should be of summary nodes.\n",
    "            self.nodesList = list(locRun.nodesColl.smry.values())\n",
    "\n",
    "        # Most likely, if you're running fixed-path mode, you'll be calling the same run with multiple playouts and\n",
    "        # comparing results across playouts.  So the code will assume that you want each playout to begin in the\n",
    "        # standard starting state (i.e., with all gates open).  If you don't want that, then just comment out this line.\n",
    "        if pathType[0] >= 0: openAllGates(self.nodesList)  # A pathType>=0 means fixed path running.\n",
    "\n",
    "        self.nPathsOpen = pathsCount(self.nodesList)\n",
    "        self.score = -999  # just set to an initial value that makes clear that it hasn't been calculated yet.\n",
    "        if eventsPerPlayout != 0:  # User requested specific number of sig/bkd events\n",
    "            self.nEvents = eventsPerPlayout  # nSig and nBkd each equals nEvents (so tot events = 2*nEvents)\n",
    "        else:  # 0 means use all events.  Since nsig must equal nbkd, set the number from the smaller set.\n",
    "            self.nEvents = min(len(self.dataset.sigWts), len(self.dataset.bkdWts))\n",
    "\n",
    "    def prepData(self):\n",
    "        \"\"\"Removes from the data the columns corresponding to unused variables and then selects the\n",
    "        requested number of events at random\"\"\"\n",
    "        # Trailing letters on \"sig\" and \"bkd\" just helps keep track of steps in manipulating\n",
    "        sigA = np.array(self.dataset.sigVars)\n",
    "        bkdA = np.array(self.dataset.bkdVars)\n",
    "\n",
    "        # Remove from the data the variables that aren't being used in this playout.\n",
    "        sigA = np.delete(sigA, self.path.excVars, 1)\n",
    "        bkdA = np.delete(bkdA, self.path.excVars, 1)\n",
    "\n",
    "        sigB = sigA.tolist()\n",
    "        bkdB = bkdA.tolist()\n",
    "\n",
    "        # Now to weighted selection of nEvents sig and nEvents bkd\n",
    "        # append weights as last column\n",
    "        sigC = MLP.joint_space(sigB, self.dataset.sigWts)\n",
    "        bkdC = MLP.joint_space(bkdB, self.dataset.bkdWts)\n",
    "\n",
    "        # Now do a weighted sampling\n",
    "        sigD = weightedSample(sigC, self.nEvents, self.dataset.sigSampleEff, self.dataset.sigWtMax)\n",
    "        bkdD = weightedSample(bkdC, self.nEvents, self.dataset.bkdSampleEff, self.dataset.bkdWtMax)\n",
    "\n",
    "        # remove the weights from the variables file.  Identify the weights column, then remove it.\n",
    "        # There isn't a +1 in identifying the weights column because kept variables/nodes are counted from zero\n",
    "        weightColumn = len(self.path.incVars)\n",
    "        sigD = np.delete(sigD, weightColumn, 1)\n",
    "        bkdD = np.delete(bkdD, weightColumn, 1)\n",
    "\n",
    "        sigD = sigD.tolist()\n",
    "        bkdD = bkdD.tolist()\n",
    "\n",
    "        return sigD, bkdD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedSample(origSample, nReq, samplingEff, weightMax):\n",
    "    \"\"\"From a sample of events (with weights as last column for each event), do a weighted sampling and\n",
    "    return a sample with the requested number of events\"\"\"\n",
    "    # figure out how big a sample of events we'll need in order, after accounting for weights, to wind up\n",
    "    # with the number of events the user requested.  Leave some headroom, since you don't know how many events\n",
    "    # culling will actually return.  The sampling eff is only the average yield you expect.\n",
    "    nEvtsInSample = len(origSample)\n",
    "    # The weight col num is one less than the length of each row, since weights are last col and col num start from 0.\n",
    "    weightColumn = len(origSample[0]) - 1\n",
    "    sampleSize = int(1.20 * nReq / samplingEff)  # scale up request to ensure enough events\n",
    "    if sampleSize > nEvtsInSample:  # num requested is too close to full sample size.  Just return original sample.\n",
    "        resultSample = origSample\n",
    "    else:\n",
    "        preWeightSel = random.sample(origSample, sampleSize)  # Get a sample that you'll do weighted selection on\n",
    "        resultSample = []\n",
    "        nSelected = 0\n",
    "        i = 0\n",
    "        while nSelected < nReq:\n",
    "            if preWeightSel[i][weightColumn] / weightMax > np.random.uniform(0, 1):\n",
    "                resultSample.append(preWeightSel[i])\n",
    "                i += 1\n",
    "                nSelected += 1\n",
    "            else:\n",
    "                i += 1\n",
    "    return resultSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go(locData):\n",
    "    \"\"\"make one pass through the data and calculate MI\"\"\"\n",
    "    sigSet = locData[0]\n",
    "    bkdSet = locData[1]\n",
    "    sigAns = []\n",
    "    bkdAns = []\n",
    "    sigAns += [[1]] * len(sigSet)\n",
    "    bkdAns += [[0]] * len(bkdSet)\n",
    "\n",
    "    # It's unclear whether or not we should only use k=1.\n",
    "    # I had seen some early signs that k>1 will lead to increasing\n",
    "    # MI even when adding just random numbers to a dataset unless\n",
    "    # the density is high enough.  That was earlier code though,\n",
    "    # so it's worth revisiting.\n",
    "    #    ksgKParameter = 1 if len(sigSet[0]) == 1 else 3\n",
    "    ksgKParameter = 1\n",
    "    sigBkdMerge = (np.concatenate((sigSet, bkdSet), axis=0)).tolist()\n",
    "    score = MLP.mi_binary(sigBkdMerge, sigAns + bkdAns, ksgKParameter)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def banditScore(locNode, cpParm):\n",
    "    \"\"\"Scores for making an include/exclude choice at a node.  The higher the score, the better the choice.\"\"\"\n",
    "    nVisitsInc = locNode.nVisitsIncPath\n",
    "    nVisitsExc = locNode.nVisitsExcPath\n",
    "    nVisitsBoth = nVisitsInc + nVisitsExc\n",
    "    meanScoreInc = locNode.sumScoreIncPath / nVisitsInc\n",
    "    meanScoreExc = locNode.sumScoreExcPath / nVisitsExc\n",
    "\n",
    "    assert nVisitsInc > 0, 'Too few visits on include side to use bandit formula'\n",
    "    assert nVisitsExc > 0, 'Too few visits on exclude side to use bandit formula'\n",
    "\n",
    "    banditInc = meanScoreInc + 2 * cpParm * np.sqrt(2 * np.log(nVisitsBoth) / nVisitsInc)\n",
    "    banditExc = meanScoreExc + 2 * cpParm * np.sqrt(2 * np.log(nVisitsBoth) / nVisitsExc)\n",
    "\n",
    "    return banditInc, banditExc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNodeID(varList, varNum):\n",
    "    \"\"\"Given a list of included variable numbers and the variable number associated with the node, return the nodeID.\n",
    "    The nodeID is such that when represented in binary, it should just show a 1 for each variable number that was\n",
    "    included on the path taken from the top of the tree to get the node.  Note that two different nodes in a tree could\n",
    "    have the same nodID.  However, they will be associated with different variables.  So, to uniquely identify a node,\n",
    "    you need its nodeID and the variable it's associated with.\"\"\"\n",
    "    nodeID = 0\n",
    "    for i in varList:\n",
    "        # When computing the ID, only use variables that are higher in the tree than the current variable.\n",
    "        # So, you only include vars with a number that's less than (not <=) the var num of the node whose ID you want.\n",
    "        if i < varNum: nodeID += 2 ** i\n",
    "    return nodeID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateNodes(locPath, score):\n",
    "    \"\"\"Given a path and a score, update the the information stored\n",
    "    for each node in the node collection.  This means both in the nested\n",
    "    dictionary for all nodes and also the list of summary nodes that are\n",
    "    one per variable\"\"\"\n",
    "    # Update the nodes that were in the path.  These are refs to the nodes that\n",
    "    # are in the full nodes dictionary, so updating the nodes in the path will\n",
    "    # update the relevant nodes in the full nested dictionary.\n",
    "    for iNode in locPath.nodesList:\n",
    "        if iNode.varNum in locPath.incVars:  # See if this node's variable is listed in the path's included variables\n",
    "            iNode.nodeStatsUpdate(score, True)  # Node's var was included in path\n",
    "        else:\n",
    "            iNode.nodeStatsUpdate(score, False)  # Node's var was NOT included in path\n",
    "\n",
    "    # Loop over the variables and for each one, update the stats for the summary node.\n",
    "    # In practice, this just means making new summary nodes, filling the values and replacing the old ones.\n",
    "    smryDict = locPath.locRun.nodesColl.smry\n",
    "    for iVar in locPath.allVars:  # Loop over all the variables in the dataset, and update the smry node for each var\n",
    "        varNodesDict = locPath.locRun.nodesColl.all[iVar]\n",
    "        varName = locPath.locRun.dataset.varNames[iVar]\n",
    "        smryNode = node(iVar, varName, locPath.locRun, iVar)  # make summary node (use varnum as its ID)\n",
    "        for key, value in varNodesDict.items():  # Loop over all existing tree nodes for this variable\n",
    "            smryNode.nodeStatsAdd(value)  # Add the tree node's info to the summary node's info\n",
    "        # for the smry nodes you have to call setgates.  For the tree nodes, it gets done in the call to nodestatsupdate\n",
    "        smryNode.setGates()\n",
    "        smryDict[iVar] = smryNode\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatesStatus(locNodeList):\n",
    "    \"\"\"\"Given a nodelist, it return a coded list that shows the gate\n",
    "    status for all the nodes. Note that this is coded in base4 so that\n",
    "    in each place, a 0 corresponds to completely closed (which should\n",
    "    never happen), a 1 corresponds to only the exclude gate open, a 2\n",
    "    corresponds to only the include gate is open, and a 3 corresponds to\n",
    "    both gates open.  So, if you pass it a list of 20 nodes, you'll get\n",
    "    a large integer that when represented in base-4 will show 0,1,2,3 in\n",
    "    each place indicating the gate status of all 20 nodes.\"\"\"\n",
    "    statusCode = 0\n",
    "    for i in range(len(locNodeList)):\n",
    "        inode = locNodeList[i]\n",
    "        nodeStatus = 0\n",
    "        if inode.excPathOpen: nodeStatus += 1\n",
    "        if inode.incPathOpen: nodeStatus += 2\n",
    "        statusCode += nodeStatus * 4 ** i\n",
    "    return statusCode\n",
    "\n",
    "\n",
    "def openAllGates(locNodeList):\n",
    "    \"\"\"\"Given a nodelist, open both gate for each node.\"\"\"\n",
    "    for currNode in locNodeList:\n",
    "        currNode.incPathOpen = True\n",
    "        currNode.excPathOpen = True\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanSigma(nEntries, sumVals, sumValsSq):\n",
    "    \"\"\"Given n, sum and sum of squares, return mean, and error on mean\"\"\"\n",
    "    if nEntries == 0:\n",
    "        mean = 0\n",
    "        errOnMean = 0\n",
    "        stdev = 0\n",
    "    else:\n",
    "        mean = sumVals / nEntries\n",
    "        variance = (sumValsSq / nEntries) - mean ** 2\n",
    "        stdev = variance ** 0.5\n",
    "        errOnMean = stdev / (nEntries ** 0.5)\n",
    "    return mean, errOnMean, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replayBest(locRun, nBest, nEvents):\n",
    "    \"\"\"Replay the paths from the top nBest playouts for a given run.  Use nEvents in each new playout.\n",
    "     Unfortunately, the current code structure does not readily allow for these to be run in parallel.\"\"\"\n",
    "    # Playout list sorted by score\n",
    "    allPlayoutsSorted = sorted(locRun.playoutList, key=lambda element: element.score, reverse=True)\n",
    "    # Get list of top nBest playouts from the run\n",
    "    topPlayouts = allPlayoutsSorted[:nBest]\n",
    "    for currPlayout in topPlayouts:\n",
    "        currPath = currPlayout.path\n",
    "        varNumList = currPath.incVars\n",
    "        playouts(locRun, nEvents, varNumList)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathsCount(nodeList):\n",
    "    \"\"\"Given a list of nodes, count the total number of paths still\n",
    "    available by looking at which gates are closed\"\"\"\n",
    "    totalPaths = 1\n",
    "    for i in nodeList:\n",
    "        nPathsCurNode = 0  # start with zero paths through node\n",
    "        if i.incPathOpen: nPathsCurNode += 1  # add 1 if inc side open\n",
    "        if i.excPathOpen: nPathsCurNode += 1  # add 1 if exc side open\n",
    "        totalPaths = totalPaths * nPathsCurNode\n",
    "    return totalPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textReports(locRun, playoutsToReport=100):\n",
    "    \"\"\"Function to call all the other main text-based report functions\"\"\"\n",
    "\n",
    "    print('Run Info')\n",
    "    runReport(locRun)\n",
    "    print('\\n', '=' * 80, '\\n')\n",
    "\n",
    "    print('Summary-Nodes Info')\n",
    "    smryNodesReport(list(locRun.nodesColl.smry.values()))\n",
    "    print('\\n', '=' * 80, '\\n')\n",
    "\n",
    "    print('Tree-Nodes Info')\n",
    "    treeNodesReport(locRun)\n",
    "    print('\\n', '=' * 80, '\\n')\n",
    "\n",
    "    print('Paths Info (sorted by pathId)')\n",
    "    pathsReport(locRun.pathStatsColl)\n",
    "    print('\\n', '=' * 80, '\\n')\n",
    "\n",
    "    print('Paths Info (sorted by mean score)')\n",
    "    pathsReport(locRun.pathStatsColl, 'mean')\n",
    "    print('\\n', '=' * 80, '\\n')\n",
    "\n",
    "    print('First', playoutsToReport, 'Playouts (0 means all)')\n",
    "    playoutsReport(locRun, playoutsToReport, False)\n",
    "    print('\\n', '=' * 80, '\\n')\n",
    "\n",
    "    print('Highest', playoutsToReport, 'Playouts (0 means all)')\n",
    "    playoutsReport(locRun, playoutsToReport, True)\n",
    "    print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runReport(locRun):\n",
    "    \"\"\"Print a summary of a run\"\"\"\n",
    "    locDataset = locRun.dataset\n",
    "\n",
    "    print('gateEvalParm =', locRun.minVisitsForGateEval, 'nodeEvalParm =', locRun.minVisitsForNodeEval,\n",
    "          'nParallel =', locRun.nParallel)\n",
    "    print(\"{0:<15s} {1:>20s} {2:>7s} {3:>7s} {4:>7s}\".\n",
    "          format(\"Dataset Info:\", \"dataset name\", \"nVar\", \"nSig\", \"nBkd\"))\n",
    "\n",
    "    print(\"{0:<15s} {1:>20s} {2:>7d} {3:>7d} {4:>7d}\".\n",
    "          format(\" \", locDataset.setName, len(locDataset.varNums), len(locDataset.sigVars), len(locDataset.bkdVars)))\n",
    "    print('-' * 60)\n",
    "    for i in range(len(locDataset.varNums)):\n",
    "        print(\"{0:>12s} {1:3d} {2:<48s}\".format(\" \", locDataset.varNums[i], locDataset.varNames[i]))\n",
    "    print('-' * 40)\n",
    "    print('Number of playouts = ', len(locRun.playoutList))\n",
    "    print('Number of fallback paths = ', locRun.nFallbackPath)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathsReport(pStatsColl, sortBy=None):\n",
    "    \"\"\"Sort the path info report by a given sort key\"\"\"\n",
    "    # first convert the dictionary into a sorted list.  This will be sorted by pathIdStr\n",
    "    if sortBy is None:\n",
    "        sortBy = []\n",
    "    sortedListTuple = sorted(pStatsColl.pathStatsDict.items(), key=operator.itemgetter(0))\n",
    "    sortedList = [row[1] for row in sortedListTuple]  # this is a list of pathStats\n",
    "\n",
    "    if sortBy == 'nVisits':\n",
    "        resortedList = sorted(sortedList, key=lambda myPathStats: myPathStats.nVisits, reverse=True)\n",
    "    elif sortBy == 'mean':\n",
    "        resortedList = sorted(sortedList, key=lambda myPathStats: myPathStats.mean, reverse=True)\n",
    "    elif sortBy == 'maxScore':\n",
    "        resortedList = sorted(sortedList, key=lambda myPathStats: myPathStats.maxScore, reverse=True)\n",
    "    else:\n",
    "        resortedList = sorted(sortedList, key=lambda myPathStats: myPathStats.pathIdStr, reverse=True)\n",
    "\n",
    "    print(\"{0:>50s}{1:>8s}{2:>9s}{3:>9s}{4:>6s}{5:>9s}\".\n",
    "          format(\"987654321098765432109876543210\", \"nVisits\", \"maxScore\", \"minScore\", \"stdev\", \"mean\"))\n",
    "    for i in resortedList:\n",
    "        \"\"\"Print one entry line in report for the current element\"\"\"\n",
    "        print(\"{0:>50s}{1:>8d}{2:>9.2f}{3:>9.2f}{4:>6.2f}{5:>5.2f}{6:>3s}{7:>5.2f}\".\n",
    "              format(i.pathIdStr, i.nVisits, i.maxScore, i.minScore, i.stdev, i.mean, \"+/-\", i.errOnMean))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smryNodesReport(nodeList):\n",
    "    \"\"\"Print a report for a given set of summary nodes.\"\"\"\n",
    "    print(\"{0:>10s} {1:>4s} {2:>5s} {3:>5s} {4:>11s} {5:>11s} {6:>7s} {7:>7s}\".\n",
    "          format(\"var\", \"var\", \"times\", \"times\", \"score when\", \"score when\", \"incGate\", \"excGate\"))\n",
    "    print(\"{0:>10s} {1:>4s} {2:>5s} {3:>5s} {4:>11s} {5:>11s} {6:>7s} {7:>7s}\".\n",
    "          format(\"name\", \"num\", \"V Inc\", \"V Exc\", \"var inc\", \"var exc\", \"Open\", \"Open\"))\n",
    "    for i in nodeList:\n",
    "        print(\"{0:>10s} {1:>4d} {2:>5d} {3:>5d} {4:>4.2f}{5:3s}{6:>4.2f} {7:>4.2f}{8:3s}{9:>4.2f} {10:>7} {11:>7}\".\n",
    "              format(i.varName, i.varNum,\n",
    "                     i.nVisitsIncPath, i.nVisitsExcPath,\n",
    "                     i.nodeOverallScore(True)[0], '+/-', i.nodeOverallScore(True)[1],\n",
    "                     i.nodeOverallScore(False)[0], '+/-', i.nodeOverallScore(False)[1],\n",
    "                     i.incPathOpen, i.excPathOpen))\n",
    "\n",
    "    currPathsOpen = pathsCount(nodeList)\n",
    "    pctPathsOpen = 100.0 * (currPathsOpen / 2 ** len(nodeList))\n",
    "    print(\"{0:35s} {1:.3e} {2:1s} {3:4.1f} {4:1s}\".\n",
    "          format(\"Current number of paths available = \", currPathsOpen, \"(\", pctPathsOpen, \"%)\"))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treeNodesReport(locRun):\n",
    "    \"\"\"Print a report on the gates for the in-tree nodes.  This is a snapshot of their status,\n",
    "    and so one likely wants to print it at multiple times during a set of playouts using\n",
    "    something like 'if playoutNum % x ==0: print...' \"\"\"\n",
    "    nodesD = locRun.nodesColl.all\n",
    "    varNumList = locRun.varNums\n",
    "    varNameList = locRun.varNames\n",
    "\n",
    "    gateSum = {}  # Make a dictionary to hold the count of how many nodes for each variable have which gate code values\n",
    "    for iVar in varNumList:  # Loop over all vars\n",
    "        gateSum[iVar] = {}  # Initialize dictionary to hold counts for each gate-status value\n",
    "        layerNodes = nodesD[iVar]  # Dictionary of the nodes for the current variable\n",
    "        for _ in range(4): gateSum[iVar][_] = 0  # Initialize the count for how many nodes are set to each gate value\n",
    "        for iNode in list(layerNodes.values()):  # Loop over nodes in the layer\n",
    "            gateCode = gatesStatus([iNode])\n",
    "            gateSum[iVar][gateCode] += 1\n",
    "\n",
    "    print('Number of nodes with each gate status for each variable after', len(locRun.playoutList), 'playouts')\n",
    "    print(\"{0:>7s} {1:>20s} {2:>9s} {3:>9s} {4:>9s} {5:>9s} {6:>9s} {7:>9s}\".\n",
    "          format(' ', ' ', 'max', 'nodes', 'nodes w/', 'nodes w/', 'nodes w/', 'nodes w/'))\n",
    "    print(\"{0:>7s} {1:>20s} {2:>9s} {3:>9s} {4:>9s} {5:>9s} {6:>9s} {7:>9s}\".\n",
    "          format('varNum', 'varName', 'nodes', 'in lyr', 'status=3', 'status=2', 'status=1', 'status=0'))\n",
    "    for i in varNumList:\n",
    "        print(\"{0:>7d} {1:>20s} {2:>9d} {3:>9d} {4:>9d} {5:>9d} {6:>9d} {7:>9d}\"\n",
    "              .format(i, varNameList[i], 2 ** i, len(list(nodesD[i].values())),\n",
    "                      gateSum[i][3], gateSum[i][2], gateSum[i][1], gateSum[i][0]))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playoutsReport(locRun, numToReport, sortByScore):\n",
    "    \"\"\"Print a summary of playouts, possibly sorted by score.  Only print numToReport rows, since\n",
    "    there could be a large number of playouts\"\"\"\n",
    "    if sortByScore:\n",
    "        myList = sorted(locRun.playoutList, key=lambda element: element.score, reverse=True)\n",
    "    else:\n",
    "        myList = locRun.playoutList\n",
    "\n",
    "    if numToReport > len(myList) or numToReport == 0: numToReport = len(myList)\n",
    "\n",
    "    print(\"{0:>4s} {1:>32s} {2:>32s} {3:>6s} {4:>7s} {5:>10s} {6:>9s} {7:>8s}\".\n",
    "          format(\" \", \"gates status for each var\", \"inc/exc status for each var\", \"play\", \" \", \"number\", \" \",\n",
    "                 \" \"))\n",
    "    print(\"{0:>4s} {1:>32s} {2:>32s} {3:>6s} {4:>7s} {5:>10s} {6:>9s} {7:>8s}\".\n",
    "          format(\"#\", \"987654321098765432109876543210\", \"987654321098765432109876543210\", \"type\", \"cpParm\",\n",
    "                 \"Paths Open\", \"nEvents\", \"score\"))\n",
    "    for i in range(0, numToReport):\n",
    "        currPlayout = myList[i]\n",
    "        ptype = currPlayout.pathType[0]\n",
    "        if ptype == -2:\n",
    "            ptypeStr = str(-2)\n",
    "        elif ptype == -1:\n",
    "            ptypeStr = str(-1)\n",
    "        else:\n",
    "            ptypeStr = 'fixed'\n",
    "        cpParm = currPlayout.cpParm\n",
    "        codedGateStatus = np.base_repr(gatesStatus(currPlayout.nodesList), 4)  # represent as string in base 4.\n",
    "        # the npaths open value only makes sense for mode = -1\n",
    "        nPathsOpenToReport = currPlayout.nPathsOpen if ptypeStr != 'fixed' else 1\n",
    "        print(\"{0:>4d} {1:>32s} {2:>32s} {3:>6s} {4:>7.3f} {5:>10.3e} {6:>9d} {7:>8.2f}\".\n",
    "              format(i, codedGateStatus, currPlayout.path.pathId()[0], ptypeStr, cpParm, nPathsOpenToReport,\n",
    "                     currPlayout.nEvents, currPlayout.score))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotReports(locRun, pdfFileName=None):\n",
    "    \"\"\"Function to call all the other main plot-based report functions\"\"\"\n",
    "\n",
    "    # Make plot of mean of score of path taken vs playout number (i.e., vs. time)\n",
    "    # Also make plot of number of paths still open vs playout number (i.e., vs. time)\n",
    "    meanResults, nPathsResults = pathTracker(locRun)\n",
    "    x = [i for i in range(len(meanResults))]\n",
    "    y1 = [meanResults[i] for i in range(len(meanResults))]\n",
    "    y2 = [math.log2(nPathsResults[i]) for i in range(len(nPathsResults))]\n",
    "\n",
    "    pdf = None\n",
    "    if pdfFileName is not None: pdf = PdfPages(pdfFileName)  # Open file for saving plots\n",
    "\n",
    "    figA1 = plt.figure()\n",
    "    plt.title('mean path score vs playout number')\n",
    "    plt.scatter(x, y1)\n",
    "    plt.show(block=False)\n",
    "\n",
    "    figA2 = plt.figure()\n",
    "    plt.title('Log (base 2) of paths open vs playout number')\n",
    "    plt.scatter(x, y2)\n",
    "    plt.show(block=False)\n",
    "\n",
    "    if pdfFileName is not None:\n",
    "        pdf.savefig(figA1)  # Save mean score of path vs playout number\n",
    "        pdf.savefig(figA2)  # Save number of paths remaining vs playout number\n",
    "\n",
    "    plt.close(figA1)\n",
    "    plt.close(figA2)\n",
    "\n",
    "    # Make plot of mean of gate status for each variable vs playout number (i.e., vs. time) and also\n",
    "    # sig/bkd overlay plots for each variable\n",
    "    for i in range(len(locRun.dataset.varNums)):\n",
    "        figGateCodes = plotGateTracker(locRun, i)\n",
    "        plt.show(block=False)\n",
    "        if pdfFileName is not None: pdf.savefig(figGateCodes)\n",
    "        plt.close(figGateCodes)\n",
    "\n",
    "    for i in range(len(locRun.dataset.varNums)):\n",
    "        figV = plotVarCompare(locRun.dataset, i)\n",
    "        plt.show(block=False)\n",
    "        if pdfFileName is not None: pdf.savefig(figV)\n",
    "        plt.close(figV)\n",
    "\n",
    "    if pdfFileName is not None: pdf.close()  # close pdf file\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathTracker(locRun):\n",
    "    \"\"\"Makes lists of quantities for all playouts.  So, for example, it\n",
    "    returns the number of paths that remained open as a function of\n",
    "    playout number.  Typically this would be used to make a plot showing\n",
    "    how some quantity evolved during the run over many playouts.\"\"\"\n",
    "    curDict = locRun.pathStatsColl.pathStatsDict\n",
    "    meanResults = []\n",
    "    nPathsResults = []\n",
    "\n",
    "    for i in locRun.playoutList:\n",
    "        curPath = i.path\n",
    "\n",
    "        curPathIdStr = curPath.pathId()[0]\n",
    "        curStats = curDict.get(curPathIdStr)\n",
    "        meanScore = curStats.mean\n",
    "        meanResults.append(meanScore)\n",
    "        nPathsResults.append(i.nPathsOpen)\n",
    "    return meanResults, nPathsResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGateTracker(locRun, varNum):\n",
    "    \"\"\"plot of gate status vs playout for a given variable\"\"\"\n",
    "    statusList = []\n",
    "    for i in locRun.playoutList:\n",
    "        statusString = np.base_repr(gatesStatus(i.nodesList), 4)  # represent as string in base 4.\n",
    "        currStatus = statusString[\n",
    "            -1 * (varNum + 1)]  # working our way backwards through the string from -1 to -(varnum+1)\n",
    "        statusList.append(int(currStatus))  # convert the status character (0,1,2,3) for the gate back to an int.\n",
    "\n",
    "    x = [i for i in range(len(locRun.playoutList))]\n",
    "    y = statusList\n",
    "    myFig = plt.figure()\n",
    "    plt.title('Gate status vs playout for var ' + str(varNum) + ': ' + locRun.dataset.varNames[varNum])\n",
    "    plt.ylim(0.0, 3.1)\n",
    "    plt.scatter(x, y)\n",
    "    return myFig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotVarCompare(locDataset, varNum):\n",
    "    \"\"\"Overlays sig and bkd hists for a given varnum in a given dataset\"\"\"\n",
    "    sig = [row[varNum] for row in locDataset.sigVars]\n",
    "    bkd = [row[varNum] for row in locDataset.bkdVars]\n",
    "\n",
    "    myFig = plt.figure()\n",
    "    plt.title(str(varNum) + ': ' + locDataset.varNames[varNum])\n",
    "    # plt.hist(sig, bins='auto', alpha=0.5, label='sig')\n",
    "    # plt.hist(bkd, bins='auto', alpha=0.5, label='bkd')\n",
    "    plt.hist([sig, bkd], bins=50, alpha=0.5, label=['sig', 'bkd'])\n",
    "    plt.legend(loc='upper right')\n",
    "    return myFig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def banditBonusDif(nA, nB, cpParm):\n",
    "    \"\"\"Returns the difference in bonus in the bandit formula for a given number of visits\n",
    "    to each side, and a given cpParm.  This isn't currently used in the main code, but it's\n",
    "    a useful utility routine for determining what value of cpParm makes sense for a problem.\"\"\"\n",
    "    nTot = nA + nB\n",
    "    banditA = 2 * cpParm * np.sqrt(2 * np.log(nTot) / nA)\n",
    "    banditB = 2 * cpParm * np.sqrt(2 * np.log(nTot) / nB)\n",
    "    return banditA, banditB, banditA-banditB"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
